{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8186858e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3414ef70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "Using GPU: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"⚠️ Using CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdc57143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory:\n",
      "c:\\Users\\chint\\OneDrive\\Documents\\Newsumm\\news_model\n",
      "\n",
      "Files here:\n",
      "['news_model', 'news_model.ipynb']\n"
     ]
    }
   ],
   "source": [
    "print(\"Current working directory:\")\n",
    "print(os.getcwd())\n",
    "\n",
    "print(\"\\nFiles here:\")\n",
    "print(os.listdir())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25566496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolved path: c:\\Users\\chint\\OneDrive\\Documents\\Newsumm\\NewsSumm Dataset.xlsx\n",
      "File exists: True\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ROOT = Path(os.getcwd()).parent\n",
    "DATA_PATH = PROJECT_ROOT / \"NewsSumm Dataset.xlsx\"\n",
    "\n",
    "print(\"Resolved path:\", DATA_PATH)\n",
    "print(\"File exists:\", DATA_PATH.exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36dccc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (348766, 6)\n",
      "Columns:\n",
      "- newspaper_name\n",
      "- published_date\n",
      "\n",
      "- headline\n",
      "- article_text\n",
      "- human_summary\n",
      "- news_category\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>newspaper_name</th>\n",
       "      <th>published_date\\n</th>\n",
       "      <th>headline</th>\n",
       "      <th>article_text</th>\n",
       "      <th>human_summary</th>\n",
       "      <th>news_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Indian Express</td>\n",
       "      <td>2020-06-01 00:00:00</td>\n",
       "      <td>Virus may be invisible enemy but COVID warrior...</td>\n",
       "      <td>Prime Minister Narendra Modi Monday hailed the...</td>\n",
       "      <td>Prime Minister of India said that the Virus ma...</td>\n",
       "      <td>National News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Economic Times</td>\n",
       "      <td>2013-02-11 00:00:00</td>\n",
       "      <td>Economy can bounce back, says PM Modi</td>\n",
       "      <td>ALLAHABAD: At least 20 persons were killed, an...</td>\n",
       "      <td>In Maha Kumbh, nearly 20 persons were killed. ...</td>\n",
       "      <td>National News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business Standard</td>\n",
       "      <td>2013-02-11 00:00:00</td>\n",
       "      <td>At least 20 killed in stampede in Allahabad</td>\n",
       "      <td>At least 20 people were killed, and scores of ...</td>\n",
       "      <td>As per the sources 20 people died and scores w...</td>\n",
       "      <td>National News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Money Control</td>\n",
       "      <td>2013-02-11 00:00:00</td>\n",
       "      <td>Maha Kumbh: Over 20 dead in Allahabad station ...</td>\n",
       "      <td>More than 20 people were feared dead and 30 ot...</td>\n",
       "      <td>At least 20 people killed and 20 people are in...</td>\n",
       "      <td>National News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Mint</td>\n",
       "      <td>2023-10-02 00:00:00</td>\n",
       "      <td>Gandhian wisdom</td>\n",
       "      <td>This Gandhi Jayanti, we should reflect upon an...</td>\n",
       "      <td>In this article, the author reflects on Mahatm...</td>\n",
       "      <td>National News</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      newspaper_name     published_date\\n  \\\n",
       "0     Indian Express  2020-06-01 00:00:00   \n",
       "1     Economic Times  2013-02-11 00:00:00   \n",
       "2  Business Standard  2013-02-11 00:00:00   \n",
       "3      Money Control  2013-02-11 00:00:00   \n",
       "4           The Mint  2023-10-02 00:00:00   \n",
       "\n",
       "                                            headline  \\\n",
       "0  Virus may be invisible enemy but COVID warrior...   \n",
       "1              Economy can bounce back, says PM Modi   \n",
       "2        At least 20 killed in stampede in Allahabad   \n",
       "3  Maha Kumbh: Over 20 dead in Allahabad station ...   \n",
       "4                                    Gandhian wisdom   \n",
       "\n",
       "                                        article_text  \\\n",
       "0  Prime Minister Narendra Modi Monday hailed the...   \n",
       "1  ALLAHABAD: At least 20 persons were killed, an...   \n",
       "2  At least 20 people were killed, and scores of ...   \n",
       "3  More than 20 people were feared dead and 30 ot...   \n",
       "4  This Gandhi Jayanti, we should reflect upon an...   \n",
       "\n",
       "                                       human_summary  news_category  \n",
       "0  Prime Minister of India said that the Virus ma...  National News  \n",
       "1  In Maha Kumbh, nearly 20 persons were killed. ...  National News  \n",
       "2  As per the sources 20 people died and scores w...  National News  \n",
       "3  At least 20 people killed and 20 people are in...  National News  \n",
       "4  In this article, the author reflects on Mahatm...  National News  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(DATA_PATH)\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"Columns:\")\n",
    "for c in df.columns:\n",
    "    print(\"-\", c)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "284412d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized columns: ['newspaper_name', 'published_date', 'headline', 'article_text', 'human_summary', 'news_category']\n"
     ]
    }
   ],
   "source": [
    "df.columns = df.columns.str.strip().str.lower()\n",
    "print(\"Normalized columns:\", list(df.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b945cada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after mapping: ['newspaper_name', 'published_date', 'text', 'article_text', 'human_summary', 'category']\n"
     ]
    }
   ],
   "source": [
    "COLUMN_MAP = {}\n",
    "\n",
    "# text column\n",
    "if \"headline\" in df.columns:\n",
    "    COLUMN_MAP[\"headline\"] = \"text\"\n",
    "elif \"text\" in df.columns:\n",
    "    COLUMN_MAP[\"text\"] = \"text\"\n",
    "\n",
    "# category column\n",
    "if \"clean_category\" in df.columns:\n",
    "    COLUMN_MAP[\"clean_category\"] = \"category\"\n",
    "elif \"news_category\" in df.columns:\n",
    "    COLUMN_MAP[\"news_category\"] = \"category\"\n",
    "elif \"category\" in df.columns:\n",
    "    COLUMN_MAP[\"category\"] = \"category\"\n",
    "\n",
    "df = df.rename(columns=COLUMN_MAP)\n",
    "\n",
    "print(\"Columns after mapping:\", list(df.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5ea7b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned shape: (348755, 6)\n",
      "category\n",
      "Politics                48796\n",
      "Business and Finance    33855\n",
      "National News           33012\n",
      "Local News              29853\n",
      "International News      26443\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(subset=[\"text\", \"category\"])\n",
    "\n",
    "df[\"text\"] = df[\"text\"].astype(str)\n",
    "df[\"category\"] = df[\"category\"].astype(str)\n",
    "\n",
    "print(\"Cleaned shape:\", df.shape)\n",
    "print(df[\"category\"].value_counts().head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4316130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "Other                   79046\n",
      "Politics                48796\n",
      "Business and Finance    33855\n",
      "National News           33012\n",
      "Local News              29853\n",
      "International News      26443\n",
      "Crime and Justice       24418\n",
      "Sports                  23290\n",
      "Entertainment           19898\n",
      "Health and Wellness     16434\n",
      "Education               13710\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "TOP_K = 10\n",
    "\n",
    "top_categories = df[\"category\"].value_counts().nlargest(TOP_K).index\n",
    "\n",
    "df[\"category\"] = df[\"category\"].apply(\n",
    "    lambda x: x if x in top_categories else \"Other\"\n",
    ")\n",
    "\n",
    "print(df[\"category\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "934f615c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 11\n",
      "Classes: ['Business and Finance' 'Crime and Justice' 'Education' 'Entertainment'\n",
      " 'Health and Wellness' 'International News' 'Local News' 'National News'\n",
      " 'Other' 'Politics' 'Sports']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"label\"] = label_encoder.fit_transform(df[\"category\"])\n",
    "\n",
    "print(\"Number of classes:\", len(label_encoder.classes_))\n",
    "print(\"Classes:\", label_encoder.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57956046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 11\n",
      "Classes: ['Business and Finance' 'Crime and Justice' 'Education' 'Entertainment'\n",
      " 'Health and Wellness' 'International News' 'Local News' 'National News'\n",
      " 'Other' 'Politics' 'Sports']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"label\"] = label_encoder.fit_transform(df[\"category\"])\n",
    "\n",
    "print(\"Number of classes:\", len(label_encoder.classes_))\n",
    "print(\"Classes:\", label_encoder.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e9e2b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chint\\OneDrive\\Documents\\Newsumm\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer loaded: distilbert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "print(\"Tokenizer loaded:\", MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b326bb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer ready\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "print(\"Tokenizer ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23ba67e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 313879\n",
      "Test size: 34876\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[\"text\"].tolist()\n",
    "y = df[\"label\"].tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.1,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(X_train))\n",
    "print(\"Test size:\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49d58910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization complete\n"
     ]
    }
   ],
   "source": [
    "def tokenize_texts(texts):\n",
    "    return tokenizer(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "X_train_tokens = tokenize_texts(X_train)\n",
    "X_test_tokens = tokenize_texts(X_test)\n",
    "\n",
    "print(\"Tokenization complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff6502c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99efdc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 313879\n",
      "Test dataset size: 34876\n"
     ]
    }
   ],
   "source": [
    "train_dataset = NewsDataset(X_train_tokens, y_train)\n",
    "test_dataset = NewsDataset(X_test_tokens, y_test)\n",
    "\n",
    "print(\"Train dataset size:\", len(train_dataset))\n",
    "print(\"Test dataset size:\", len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3549fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded with 11 classes\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "num_labels = len(label_encoder.classes_)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=num_labels\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(\"Model loaded with\", num_labels, \"classes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c809eb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training arguments ready\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./news_model\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=200,\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\",\n",
    "    fp16=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "print(\"Training arguments ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ee9c400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chint\\AppData\\Local\\Temp\\ipykernel_15528\\2553122640.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(\"Trainer initialized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a951ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39236' max='39236' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39236/39236 1:25:34, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.214500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.202700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.180200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.164900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.171700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.128200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.127600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>1.127400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>1.131100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.124600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>1.101600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.119000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>1.088900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>1.087100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.072400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>1.097500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>1.086300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>1.066300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>1.131500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.068900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>1.060400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>1.071200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>1.069600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>1.053400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.034700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>1.093900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>1.077300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>1.072500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>1.056800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.020700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>1.074700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>1.103500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>1.092600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>1.055000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.082800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>1.044800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>1.071500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>1.043500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>1.042300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>1.028200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>1.086000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>1.054100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>1.038500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>1.076400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.033100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>1.072100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9400</td>\n",
       "      <td>1.101900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>1.084100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9800</td>\n",
       "      <td>1.058700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.038500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10200</td>\n",
       "      <td>1.061700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10400</td>\n",
       "      <td>1.056400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10600</td>\n",
       "      <td>1.092900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10800</td>\n",
       "      <td>1.011400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>1.036900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11200</td>\n",
       "      <td>1.072000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11400</td>\n",
       "      <td>1.011300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11600</td>\n",
       "      <td>1.048200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11800</td>\n",
       "      <td>1.061800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>1.048900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12200</td>\n",
       "      <td>1.037600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12400</td>\n",
       "      <td>1.051500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12600</td>\n",
       "      <td>1.062300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12800</td>\n",
       "      <td>1.055100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>1.071400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13200</td>\n",
       "      <td>1.012700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13400</td>\n",
       "      <td>1.042200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13600</td>\n",
       "      <td>1.061200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13800</td>\n",
       "      <td>1.052400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>1.049800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14200</td>\n",
       "      <td>1.074000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14400</td>\n",
       "      <td>1.055400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14600</td>\n",
       "      <td>1.032700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14800</td>\n",
       "      <td>1.091700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>1.065700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15200</td>\n",
       "      <td>1.066300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15400</td>\n",
       "      <td>1.076400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15600</td>\n",
       "      <td>1.063800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15800</td>\n",
       "      <td>1.107100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>1.071600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16200</td>\n",
       "      <td>1.090900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16400</td>\n",
       "      <td>1.058800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16600</td>\n",
       "      <td>1.095900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16800</td>\n",
       "      <td>1.100900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>1.094000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17200</td>\n",
       "      <td>1.097200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17400</td>\n",
       "      <td>1.072700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17600</td>\n",
       "      <td>1.076100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17800</td>\n",
       "      <td>1.074100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>1.088500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18200</td>\n",
       "      <td>1.062700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18400</td>\n",
       "      <td>1.068900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18600</td>\n",
       "      <td>1.115100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18800</td>\n",
       "      <td>1.091100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>1.112200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19200</td>\n",
       "      <td>1.107900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19400</td>\n",
       "      <td>1.108900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19600</td>\n",
       "      <td>1.078700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19800</td>\n",
       "      <td>1.034300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>1.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20200</td>\n",
       "      <td>1.021700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20400</td>\n",
       "      <td>1.065000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20600</td>\n",
       "      <td>1.045200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20800</td>\n",
       "      <td>1.034100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>1.021300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21200</td>\n",
       "      <td>1.029700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21400</td>\n",
       "      <td>1.073700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21600</td>\n",
       "      <td>1.056200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21800</td>\n",
       "      <td>1.072400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>1.065000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22200</td>\n",
       "      <td>1.006600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22400</td>\n",
       "      <td>1.044800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22600</td>\n",
       "      <td>1.033200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22800</td>\n",
       "      <td>1.008800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>1.054500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23200</td>\n",
       "      <td>1.034800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23400</td>\n",
       "      <td>1.053500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23600</td>\n",
       "      <td>1.049200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23800</td>\n",
       "      <td>1.025500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>1.028800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24200</td>\n",
       "      <td>1.025100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24400</td>\n",
       "      <td>1.021200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24600</td>\n",
       "      <td>1.069300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24800</td>\n",
       "      <td>1.022900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>1.054600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25200</td>\n",
       "      <td>1.049200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25400</td>\n",
       "      <td>1.055000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25600</td>\n",
       "      <td>1.052200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25800</td>\n",
       "      <td>1.034600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>1.038700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26200</td>\n",
       "      <td>1.077500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26400</td>\n",
       "      <td>1.045900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26600</td>\n",
       "      <td>1.055200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26800</td>\n",
       "      <td>1.036800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>1.054800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27200</td>\n",
       "      <td>1.055800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27400</td>\n",
       "      <td>1.019800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27600</td>\n",
       "      <td>1.080600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27800</td>\n",
       "      <td>1.060600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>1.058100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28200</td>\n",
       "      <td>1.048100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28400</td>\n",
       "      <td>1.012400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28600</td>\n",
       "      <td>1.037700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28800</td>\n",
       "      <td>1.036500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>1.023400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29200</td>\n",
       "      <td>0.993800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29400</td>\n",
       "      <td>1.027400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29600</td>\n",
       "      <td>1.011200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29800</td>\n",
       "      <td>1.054500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>1.019900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30200</td>\n",
       "      <td>1.040100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30400</td>\n",
       "      <td>1.037600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30600</td>\n",
       "      <td>1.036800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30800</td>\n",
       "      <td>1.026500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>1.015600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31200</td>\n",
       "      <td>1.028200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31400</td>\n",
       "      <td>1.054700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31600</td>\n",
       "      <td>1.035900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31800</td>\n",
       "      <td>1.048600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>1.035400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32200</td>\n",
       "      <td>1.009600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32400</td>\n",
       "      <td>0.990800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32600</td>\n",
       "      <td>1.034000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32800</td>\n",
       "      <td>1.036500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>1.048700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33200</td>\n",
       "      <td>1.057900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33400</td>\n",
       "      <td>1.035300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33600</td>\n",
       "      <td>1.049800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33800</td>\n",
       "      <td>1.023400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>1.026800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34200</td>\n",
       "      <td>1.032500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34400</td>\n",
       "      <td>1.039200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34600</td>\n",
       "      <td>1.044700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34800</td>\n",
       "      <td>1.020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>1.058300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35200</td>\n",
       "      <td>0.996000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35400</td>\n",
       "      <td>1.004500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35600</td>\n",
       "      <td>1.015600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35800</td>\n",
       "      <td>1.017400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>1.011900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36200</td>\n",
       "      <td>1.027100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36400</td>\n",
       "      <td>1.045700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36600</td>\n",
       "      <td>1.027400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36800</td>\n",
       "      <td>1.054100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>1.035700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37200</td>\n",
       "      <td>1.027800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37400</td>\n",
       "      <td>1.011300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37600</td>\n",
       "      <td>1.070400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37800</td>\n",
       "      <td>1.057600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>1.042300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38200</td>\n",
       "      <td>1.035500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38400</td>\n",
       "      <td>0.999400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38600</td>\n",
       "      <td>1.039500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38800</td>\n",
       "      <td>1.034200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>1.049400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39200</td>\n",
       "      <td>1.027000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=39236, training_loss=1.0579102994810126, metrics={'train_runtime': 5135.1089, 'train_samples_per_second': 122.248, 'train_steps_per_second': 7.641, 'total_flos': 2.0792704051047936e+16, 'train_loss': 1.0579102994810126, 'epoch': 2.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6142a99e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Save final trained model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtrainer\u001b[49m.save_model(\u001b[33m\"\u001b[39m\u001b[33m./news_model/final_model\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Save tokenizer (CRITICAL for inference)\u001b[39;00m\n\u001b[32m      5\u001b[39m tokenizer.save_pretrained(\u001b[33m\"\u001b[39m\u001b[33m./news_model/final_model\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "# Save final trained model\n",
    "trainer.save_model(\"./news_model/final_model\")\n",
    "\n",
    "# Save tokenizer (CRITICAL for inference)\n",
    "tokenizer.save_pretrained(\"./news_model/final_model\")\n",
    "\n",
    "print(\"Final model and tokenizer saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e64feea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset ready: Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 34876\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "test_dataset = Dataset.from_dict({\n",
    "    \"input_ids\": X_test_tokens[\"input_ids\"],\n",
    "    \"attention_mask\": X_test_tokens[\"attention_mask\"],\n",
    "    \"labels\": y_test\n",
    "})\n",
    "\n",
    "print(\"Test dataset ready:\", test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a61cd7e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4360' max='4360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4360/4360 01:27]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.3891608715057373, 'eval_model_preparation_time': 0.0061, 'eval_runtime': 88.8439, 'eval_samples_per_second': 392.554, 'eval_steps_per_second': 49.075}\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate(test_dataset)\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dee7693",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9dc8fb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on: cuda\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"./news_model/final_model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./news_model/final_model\")\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded on:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8bb1bc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_category(text):\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=128\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    pred_label_id = outputs.logits.argmax(dim=1).item()\n",
    "    return label_encoder.inverse_transform([pred_label_id])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8295c77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted category: Entertainment\n"
     ]
    }
   ],
   "source": [
    "headline = \"The film is a flop\"\n",
    "print(\"Predicted category:\", predict_category(headline))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
